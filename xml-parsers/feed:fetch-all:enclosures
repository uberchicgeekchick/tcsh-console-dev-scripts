#!/usr/bin/tcsh -f
if (! ${?1} || "${1}" == "" || "${1}" == "--help" ) then
	printf "Usage: %s [--newest|--get-first=1..10..?|--get-last=1..10..?] RSS_URI\n" `basename ${0}`;
	exit -1;
endif

set attrib = "`printf '${1}' | sed 's/\-\-\([^=]*\)=\?\(.*\)/\1/g'`";
set value = "`printf '${1}' | sed 's/\-\-\([^=]*\)=\?\(.*\)/\2/g'`";

switch ( "${attrib}" )
case "newest":
	shift;
	set first_episodes = "1";
	breaksw

case "first":
	shift;
	set first_episodes = "${value}";
	breaksw

case "last":
	shift;
	set last_episodes = "${value}";
	breaksw

case "quiet":
	shift;
	set quiet;
	breaksw

case "regex-match-titles":
	shift;
	if ( "${value}" == "" ) breaksw
	set regex_match_titles = "${value}";
	breaksw
endsw

set please_wait_phrase="...please be patient, I may need several moments.\t\t";

if( ! ${?quiet} ) printf "Downloading podcast's feed.\n"
wget --quiet -O './00-feed.xml' "${1}"

if( ! ${?quiet} ) printf "Finding feed's title.\n"
set title = "`/usr/bin/grep '<title.*>' './00-feed.xml' | sed 's/.*<title[^>]*>\([^<]*\)<\/title>.*/\1/gi' | head -1 | sed 's/[\r\n]//g' | sed 's/\//\ \-\ /g'`"

if ( ! -d "${title}" ) mkdir -p "${title}"
cd "${title}"

set download_log = "./00-"`basename "${0}"`".log"
touch "${download_log}"

if( ! ${?quiet} ) printf "Preparing to download: %s\n" "${title}"
printf "Preparing to download: %s\n" "${title}" >> "${download_log}"
if( ! ${?quiet} ) printf "\tURI:\n\t%s\n" "${1}"
printf "\tURI:\n\t%s\n" "${1}" >> "${download_log}"

if ( -e './00-feed.xml' && -e './00-titles.lst' && -e './00-enclosures.lst' && -e './00-pubdates.lst' ) goto continue_download

mv '../00-feed.xml' "./00-feed.xml"

# Grabs the titles of the podcast and all episodes.
if( ! ${?quiet} ) printf "Finding title${please_wait_phrase}"
printf "Finding titles${please_wait_phrase}" >> "${download_log}"
cp './00-feed.xml' './00-titles.lst'

# Concatinates all data into one single string:
ex '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/<\/\(item\|entry\)>/<\/\1>\r/ig' '+1,$s/.*<\(item\|entry\)>.*<title[^>]*>\(.*\)<\/title>.*\(enclosure\).*<\/\(item\|entry\)>$/\2/ig' '+1,$s/.*<\(item\|entry\)>.*<title[^>]*>\([^<]*\)<\/title>.*<\/\(item\|entry\)>[\n\r]*//ig' '+$d' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/&\(#038\|amp\)\;/\&/ig' '+1,$s/&\(#8243\|#8217\|#8220\|#8221\|\#039\|rsquo\|lsquo\)\;/'\''/ig' '+1,$s/&[^;]\+\;[\ \t]*//ig' '+1,$s/<\!\[CDATA\[\(.*\)\]\]>/\1/g' '+1,$s/#//g' '+1,$s/\//\ \-\ /g' '+wq' './00-titles.lst' >& /dev/null
if( ! ${?quiet} )printf "[done]\n"
printf "[done]\n" >> "${download_log}"

# This will be my last update to any part of Alacast v1
# This fixes episode & chapter titles so that they will sort correctly
if( ! ${?quiet} ) printf "Formating titles${please_wait_phrase}"
printf "Formating titles${please_wait_phrase}" >> "${download_log}"
ex '+1,$s/^\(Zero\)/0/gi' '+1,$s/^\(One\)/1/gi' '+1,$s/^\(Two\)/2/gi' '+1,$s/^\(Three\)/3/gi' '+1,$s/^\(Four\)/4/gi' '+1,$s/^\(Five\)/5/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/^\(Six\)/6/gi' '+1,$s/^\(Seven\)/7/gi' '+1,$s/^\(Eight\)/8/gi' '+1,$s/^\(Nine\)/9/gi' '+1,$s/^\(Ten\)/10/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/^\([0-9]\)ty/\10/gi' '+1,$s/^\(Fifty\)/50/gi' '+1,$s/^\(Thirty\)/30/gi' '+1,$s/^\(Twenty\)/20/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/^\([0-9]\)teen/1\1/gi' '+1,$s/^\(Fifteen\)/15/gi' '+1,$s/^\(Thirteen\)/13/gi' '+1,$s/^\(Twelve\)/12/gi' '+1,$s/^\(Eleven\)/11/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/[^a-zA-Z]\(Zero\)/0/gi' '+1,$s/[^a-zA-Z]\(One\)/1/gi' '+1,$s/[^a-zA-Z]\(Two\)/2/gi' '+1,$s/[^a-zA-Z]\(Three\)/3/gi' '+1,$s/[^a-zA-Z]\(Four\)/4/gi' '+1,$s/[^a-zA-Z]\(Five\)/5/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/[^a-zA-Z]\(Six\)/6/gi' '+1,$s/[^a-zA-Z]\(Seven\)/7/gi' '+1,$s/[^a-zA-Z]\(Eight\)/8/gi' '+1,$s/[^a-zA-Z]\(Nine\)/9/gi' '+1,$s/[^a-zA-Z]\(Ten\)/10/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/[^a-zA-Z]\([0-9]\)ty/\10/gi' '+1,$s/[^a-zA-Z]\(Fifty\)/50/gi' '+1,$s/[^a-zA-Z]\(Thirty\)/30/gi' '+1,$s/[^a-zA-Z]\(Twenty\)/20/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/[^a-zA-Z]\([0-9]\)teen/1\1/gi' '+1,$s/[^a-zA-Z]\(Fifteen\)/15/gi' '+1,$s/[^a-zA-Z]\(Thirteen\)/13/gi' '+1,$s/[^a-zA-Z]\(Twelve\)/12/gi' '+1,$s/[^a-zA-Z]\(Eleven\)/11/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/^\([0-9]\{1\}\)\([^0-9]\{1\}\)/0\1\2/' '+1,$s/\([^0-9]\{1\}\)\([0-9]\{1\}\)\([^0-9]\{1\}\)/\10\2\3/g' '+1,$s/\([^0-9]\{1\}\)\([0-9]\{1\}\)$/\10\2/' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/\//\ \-\ /g' '+1,$s/[\ ]\{2,\}/\ /g' '+wq' './00-titles.lst' >& /dev/null
if( ! ${?quiet} ) printf "[done]\n"
printf "[done]\n" >> "${download_log}"


# Grabs the release dates of the podcast and all episodes.
if( ! ${?quiet} ) printf "Finding release dates...please be patient, I may need several moments\t\t"
printf "Finding release dates${please_wait_phrase}\t\t" >> "${download_log}"
cp './00-feed.xml' './00-pubdates.lst'

# Concatinates all data into one single string:
ex '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-pubdates.lst' >& /dev/null
ex '+1,$s/<\/\(item\|entry\)>/\<\/\1\>\r/ig' '+1,$s/.*<\(item\|entry\)>.*<\(pubDate\|updated\)[^>]*>\(.*\)<\/\(pubDate\|updated\)>.*<.*enclosure[^>]*\(url\|href\)=["'\'']\([^"'\'']\+\)["'\''].*<\/\(item\|entry\)>$/\3/ig' '+1,$s/.*<\(item\|entry\)>.*<\(pubDate\|updated\)[^>]*>\([^<]*\)<\/\(pubDate\|updated\)>.*<\/\(item\|entry\)>[\n\r]*//ig' '+$d' '+wq' './00-pubdates.lst' >& /dev/null

if( ! ${?quiet} ) printf "[done]\n"
printf "[done]\n" >> "${download_log}"


# Grabs the enclosures from the feed.
# This 1st method only grabs one enclosure per item/entry.
if( ! ${?quiet} ) printf "Finding enclosures . . . this may take a few moments\t\t"
printf "Finding enclosures . . . this may take a few moments\t\t" >> "${download_log}"
cp '00-feed.xml' '00-enclosures-01.lst'

# Concatinates all data into one single string:
ex '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-enclosures-01.lst' >& /dev/null

ex '+1,$s/<\/\(item\|entry\)>/\<\/\1\>\r/ig' '+1,$s/.*<\(item\|entry\)>.*<title[^>]*>\(.*\)<\/title>.*<.*enclosure[^>]*\(url\|href\)=["'\'']\([^"'\'']\+\)["'\''].*<\/\(item\|entry\)>$/\4/ig' '+1,$s/.*<\(item\|entry\)>.*<title[^>]*>\([^<]*\)<\/title>.*<\/\(item\|entry\)>[\n\r]*//ig' '+$d' '+wq' '00-enclosures-01.lst' >& /dev/null
ex '+1,$s/^[\ \s\r\n]\+//g' '+1,$s/[\ \s\r\n]\+$//g' '+1,$s/?/\\?/g' '+wq' './00-enclosures-01.lst' >& /dev/null

# This second method grabs all enclosures.
cp '00-feed.xml' '00-enclosures-02.lst'

# Concatinates all data into one single string:
ex '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-enclosures-02.lst' >& /dev/null

/usr/bin/grep --perl-regex '.*<.*enclosure[^>]*>.*' './00-enclosures-02.lst' | sed 's/.*url=["'\'']\([^"'\'']\+\)["'\''].*/\1/gi' | sed 's/.*<link[^>]\+href=["'\'']\([^"'\'']\+\)["'\''].*/\1/gi' | sed 's/^\(http:\/\/\).*\(http:\/\/.*$\)/\2/gi' | sed 's/<.*>[\r\n]\+//ig' >! './00-enclosures-02.lst'
ex '+1,$s/^[\ \s\r\n]\+//g' '+1,$s/[\ \s\r\n]\+$//g' '+1,$s/?/\\?/g' '+wq' './00-enclosures-02.lst' >& /dev/null

set enclosure_count_01 = `cat "./00-enclosures-01.lst"`
set enclosure_count_02 = `cat "./00-enclosures-02.lst"`
if ( ${#enclosure_count_01} >= ${#enclosure_count_02} ) then
	mv "./00-enclosures-01.lst" "./00-enclosures.lst"
	rm "./00-enclosures-02.lst"
else
	mv "./00-enclosures-02.lst" "./00-enclosures.lst"
	rm "./00-enclosures-01.lst"
endif
if( ! ${?quiet} ) printf "[done]\n"
printf "[done]\n" >> "${download_log}"

if( ! ${?quiet} ) printf "Beginning to download: %s\n" "${title}"
printf "Beginning to download: %s\n" "${title}" >> "${download_log}"
set episodes = ();
if ( ${?first_episodes} ) then
	if( ${#first_episodes} > 0 ) then
		set episodes = "`head -${first_episodes} './00-enclosures.lst'`"
		head -${first_episodes} './00-titles.lst' >! './00-tmp-titles.lst'
		mv './00-tmp-titles.lst' './00-titles.lst'
	endif
else if ( ${?last_episodes} ) then
	if( ${#last_episodes} > 0 ) then
		set episodes = "`tail -${last_episodes} './00-enclosures.lst'`"
		tail -${last_episodes} './00-titles.lst' >! './00-tmp-titles.lst'
		mv './00-tmp-titles.lst' './00-titles.lst'
	endif
else
	set episodes = "`cat './00-enclosures.lst'`"
endif

goto download_episodes

continue_download:
rm  "../00-feed.xml"
set episodes = "`cat './00-enclosures.lst'`"

download_episodes:

if( ! ${?quiet} ) printf "\n\tI have found %s episodes of:\n\t\t'%s'\n\n" "${#episodes}" "${title}"
printf "\n\tI have found %s episodes of:\n\t\t'%s'\n\n" "${#episodes}" "${title}" >! "${download_log}"

@ episodes_downloaded=0;
@ episode_number=0;
foreach episode ( $episodes )
	@ episode_number++;
	set episode = `echo "${episode}" | sed 's/[\r\n]$//'`
	set episodes_file = `basename ${episode}`
	set extension = `printf '%s' "${episodes_file}" | sed 's/.*\.\([^.]*\)$/\1/'`

	set episodes_pubdate = "`cat './00-pubdates.lst' | head -${episode_number} | tail -1 | sed 's/[\r\n]//g' | sed 's/\?//g'`"
	
	set episodes_title = "`cat './00-titles.lst' | head -${episode_number} | tail -1 | sed 's/[\r\n]//g' | sed 's/\?//g'`"
	
	if ( "${episodes_title}" == "" ) set episodes_title = `printf '%s' "${episodes_filename}" | sed 's/\(.*\)\.[^.]*$/\1/'`
	
	set episodes_filename = "${episodes_title}, released on ${episodes_pubdate}.${extension}";
	
	if( ! ${?quiet} ) printf "\n\n\t\tFound episode: %s\n\t\tTitle: %s\n\t\tReleased on: %s\n\t\tURL: %s\n\t\t\t" "${episodes_title}" "${episodes_title}" "${episodes_pubdate}" "${episode}";
	printf "\n\n\t\tDownloading episode: %s\n\t\tTitle: %s\n\t\tReleased on: %s\n\t\tFilename: %s\n\t\tRemote file: %s\n\t\tURL: %s\n\t\t\t" ${episode_number} "${episodes_title}" "${episodes_pubdate}" "${episodes_filename}" "${episodes_file}" "${episode}" >> "${download_log}"

	# Skipping existing files.
	if ( -e "./${episodes_filename}" ) then
		if( ! ${?quiet} ) printf "[skipped existing file]\n\n"
		printf "[skipping existing file]\n\n" >> "${download_log}"
		continue
	endif
	
	switch ( "${episodes_file}" )
	case "theend.mp3":
	case "caughtup.mp3":
	case "caught_up_1.mp3":
		if( ! ${?quiet} ) printf "[skipping podiobook.com notice]\n\n"
		printf "[skipping podiobook.com notice]\n\n" >> "${download_log}"
		continue
		breaksw
	endsw

	set is_commentary = `printf "${episodes_file}==${episodes_filename}" | sed 's/.*\([Cc]ommentary\).*/\1/gi'`
	if ( "${is_commentary}" != `printf "${episodes_file}==${episodes_filename}"` ) then
		if( ! ${?quiet} ) printf "[skipped commentary track]\n\n"
		printf "[skipped commentary track]\n\n" >> "${download_log}"
		continue
	endif

	if ( ${?regex_match_titles} ) then
		if ( "`echo ${episodes_title} | s/.*\(${regex_match_titles}\).*/\1/g'`" )=="${regex_match_titles}" ) then
			printf "[skipping regexp matched episode]";
			continue;
		endif
	endif

	wget --quiet -O "./${episodes_filename}" "${episode}"
	if ( ! -e "./${episodes_filename}" ) then
		if( ! ${?quiet} ) printf "[*epic fail* :(]\n\n"
		printf "[*pout* :(]\n\n" >> "${download_log}"
	else
		if( ! ${?quiet} ) printf "[*w00t\!*, FTW\!]\n\n"
		@ episodes_downloaded++;
		printf "[*w00t\!*, FTW\!]\n\n" >> "${download_log}"
	endif
end

if( ! ${?quiet} ) printf "*w00t\!*, I'm done; enjoy online media at its best!"
printf "*w00t\!*, I'm done; enjoy online media at its best!" >> "${download_log}"

if ( ! ( ${?2} && "${2}" == "---enable-debug" ) ) rm './00-titles.lst' './00-enclosures.lst' './00-pubdates.lst' './00-feed.xml'

