#!/usr/bin/tcsh -f
if(! ${?1} || "${1}" == "" || "${1}" == "--help" ) then
	printf "Usage: %s [ (--newest|--first)=1..10..? ] [ (--oldest|--last)=1..10..? ] [ --quit ] RSS_URI\n" `basename ${0}`;
	exit -1;
endif

while( ${?1} && "${1}" != "" )
	set attrib = "`printf '${1}' | sed 's/\-\-\([^=]*\)=\?\(.*\)/\1/g'`";
	set value = "`printf '${1}' | sed 's/\-\-\([^=]*\)=\?\(.*\)/\2/g'`";
	
	switch ( "${attrib}" )
	case "newest":
	case "first":
		shift;
		if( ${?value} && "${value}" != "" && ${value} > 0 ) then
			set download_first="${value}";
		else
			set download_first="1";
		endif
		breaksw
	
	case "start-with-episode":
	case "start-with":
	case "start-at-episode":
	case "start-at":
		shift;
		if( ${?value} && "${value}" != "" && ${value} > 0 ) then
			set first_episodes="${value}";
		else
			set first_episodes="1";
		endif
		breaksw
	
	case "oldest":
	case "last":
	case "stop-with-episode":
	case "stop-with":
	case "stop-at-episode":
	case "stop-at":
		shift;
		if( ${?value} && "${value}" != "" && ${value} > 0 ) then
			set last_episodes="${value}";
		else
			set last_episodes = "1";
		endif
		breaksw
	
	case "quiet":
		shift;
		set quiet;
		breaksw
	
	case "regex-match-titles":
		shift;
		if( "${value}" == "" ) breaksw
		set regex_match_titles = "${value}";
		breaksw
	
	default:
		set feed="${1}";
		shift;
		breaksw
	endsw

end	
set please_wait_phrase="...please be patient, I may need several moments.\t\t";

if( ! ${?quiet} ) printf "Downloading podcast's feed.\n"
wget --quiet -O './00-feed.xml' "${feed}"

if( ! ${?quiet} ) printf "Finding feed's title.\n"
set title = "`/usr/bin/grep '<title.*>' './00-feed.xml' | sed 's/.*<title[^>]*>\([^<]*\)<\/title>.*/\1/gi' | head -1 | sed 's/[\r\n]//g' | sed 's/\//\ \-\ /g' | sed  's/[\ \t]*\&[^;]\+\;[\ \t]*/\ /ig'`";

if( ! -d "${title}" ) mkdir -p "${title}"
cd "${title}"

set download_log = "./00-"`basename "${0}"`".log"
touch "${download_log}"

if( ! ${?quiet} ) printf "Preparing to download: %s\n" "${title}"
printf "Preparing to download: %s\n" "${title}" >> "${download_log}"
if( ! ${?quiet} ) printf "\tURI:\t[%s]\n" "${feed}"
printf "\tURI:\t[%s]\n" "${feed}" >> "${download_log}"

if( -e './00-feed.xml' && -e './00-titles.lst' && -e './00-enclosures.lst' && -e './00-pubdates.lst' ) goto continue_download

mv '../00-feed.xml' "./00-feed.xml"

# Grabs the titles of the podcast and all episodes.
if( ! ${?quiet} ) printf "Finding title${please_wait_phrase}\t"
printf "Finding titles${please_wait_phrase}\t" >> "${download_log}"
cp './00-feed.xml' './00-titles.lst'

# Concatinates all data into one single string:
ex '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/<\/\(item\|entry\)>/<\/\1>\r/ig' '+1,$s/.*<\(item\|entry\)>.*<title[^>]*>\(.*\)<\/title>.*\(enclosure\).*<\/\(item\|entry\)>$/\2/ig' '+1,$s/.*<\(item\|entry\)>.*<title[^>]*>\([^<]*\)<\/title>.*<\/\(item\|entry\)>[\n\r]*//ig' '+$d' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/&\(#038\|amp\)\;/\&/ig' '+1,$s/&\(#8243\|#8217\|#8220\|#8221\|\#039\|rsquo\|lsquo\)\;/'\''/ig' '+1,$s/&[^;]\+\;[\ \t]*/\ /ig' '+1,$s/<\!\[CDATA\[\(.*\)\]\]>/\1/g' '+1,$s/#//g' '+1,$s/\//\ \-\ /g' '+wq' './00-titles.lst' >& /dev/null
if( ! ${?quiet} )printf "[done]\n"
printf "[done]\n" >> "${download_log}"

# This will be my last update to any part of Alacast v1
# This fixes episode & chapter titles so that they will sort correctly
if( ! ${?quiet} ) printf "Formating titles${please_wait_phrase}"
printf "Formating titles${please_wait_phrase}" >> "${download_log}"
ex '+1,$s/^\(Zero\)/0/gi' '+1,$s/^\(One\)/1/gi' '+1,$s/^\(Two\)/2/gi' '+1,$s/^\(Three\)/3/gi' '+1,$s/^\(Four\)/4/gi' '+1,$s/^\(Five\)/5/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/^\(Six\)/6/gi' '+1,$s/^\(Seven\)/7/gi' '+1,$s/^\(Eight\)/8/gi' '+1,$s/^\(Nine\)/9/gi' '+1,$s/^\(Ten\)/10/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/^\([0-9]\)ty/\10/gi' '+1,$s/^\(Fifty\)/50/gi' '+1,$s/^\(Thirty\)/30/gi' '+1,$s/^\(Twenty\)/20/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/^\([0-9]\)teen/1\1/gi' '+1,$s/^\(Fifteen\)/15/gi' '+1,$s/^\(Thirteen\)/13/gi' '+1,$s/^\(Twelve\)/12/gi' '+1,$s/^\(Eleven\)/11/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/\([^a-zA-Z]\)\(Zero\)/\10/gi' '+1,$s/\([^a-zA-Z]\)\(One\)/\11/gi' '+1,$s/\([^a-zA-Z]\)\(Two\)/\12/gi' '+1,$s/\([^a-zA-Z]\)\(Three\)/\13/gi' '+1,$s/\([^a-zA-Z]\)\(Four\)/\14/gi' '+1,$s/\([^a-zA-Z]\)\(Five\)/\15/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/\([^a-zA-Z]\)\(Six\)/\16/gi' '+1,$s/\([^a-zA-Z]\)\(Seven\)/\17/gi' '+1,$s/\([^a-zA-Z]\)\(Eight\)/\18/gi' '+1,$s/\([^a-zA-Z]\)\(Nine\)/\19/gi' '+1,$s/\([^a-zA-Z]\)\(Ten\)/\110/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/\([^a-zA-Z]\)\([0-9]\)ty[^a-zA-Z]/\1\20/gi' '+1,$s/\([^a-zA-Z]\)\(Fifty\)\([^a-zA-Z]\)/\150\3/gi' '+1,$s/\([^a-zA-Z]\)\(Thirty\)\([^a-zA-Z]\)/\130\3/gi' '+1,$s/\([^a-zA-Z]\)\(Twenty\)\([^a-zA-Z]\)/\120\3/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/\([^a-zA-Z]\)\([0-9]\)teen\([^a-zA-Z]\)/\11\2\3/gi' '+1,$s/\([^a-zA-Z]\)\(Fifteen\)\([^a-zA-Z]\)/\115\3/gi' '+1,$s/\([^a-zA-Z]\)\(Thirteen\)\([^a-zA-Z]\)/\113\3/gi' '+1,$s/\([^a-zA-Z]\)\(Twelve\)\([^a-zA-Z]\)/\112\3/gi' '+1,$s/\([^a-zA-Z]\)\(Eleven\)\([^a-zA-Z]\)/\111\3/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/\([^a-zA-Z]\)\([0-9]\)ty/\1\20$/gi' '+1,$s/\([^a-zA-Z]\)\(Fifty\)/\150/gi' '+1,$s/\([^a-zA-Z]\)\(Thirty\)/\130/gi' '+1,$s/\([^a-zA-Z]\)\(Twenty\)/\120/gi' '+wq' './00-titles.lst' >& /dev/null
ex '+1,$s/\([^a-zA-Z]\)\([0-9]\)teen/\11\2$/gi' '+1,$s/\([^a-zA-Z]\)\(Fifteen\)/\115/gi' '+1,$s/\([^a-zA-Z]\)\(Thirteen\)/\113/gi' '+1,$s/\([^a-zA-Z]\)\(Twelve\)/\112/gi' '+1,$s/\([^a-zA-Z]\)\(Eleven\)/\111/gi' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/^\([0-9]\{1\}\)\([^0-9]\{1\}\)/0\1\2/' '+1,$s/\([^0-9]\{1\}\)\([0-9]\{1\}\)\([^0-9]\{1\}\)/\10\2\3/g' '+1,$s/\([^0-9]\{1\}\)\([0-9]\{1\}\)$/\10\2/' '+wq' './00-titles.lst' >& /dev/null

ex '+1,$s/\//\ \-\ /g' '+1,$s/[\ ]\{2,\}/\ /g' '+wq' './00-titles.lst' >& /dev/null
if( ! ${?quiet} ) printf "[done]\n"
printf "[done]\n" >> "${download_log}"


# Grabs the release dates of the podcast and all episodes.
if( ! ${?quiet} ) printf "Finding release dates...please be patient, I may need several moments\t\t"
printf "Finding release dates${please_wait_phrase}\t\t" >> "${download_log}"
cp './00-feed.xml' './00-pubdates.lst'

# Concatinates all data into one single string:
ex '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-pubdates.lst' >& /dev/null
ex '+1,$s/<\/\(item\|entry\)>/\<\/\1\>\r/ig' '+1,$s/.*<\(item\|entry\)>.*<\(pubDate\|updated\)[^>]*>\(.*\)<\/\(pubDate\|updated\)>.*<.*enclosure[^>]*\(url\|href\)=["'\'']\([^"'\'']\+\)["'\''].*<\/\(item\|entry\)>$/\3/ig' '+1,$s/.*<\(item\|entry\)>.*<\(pubDate\|updated\)[^>]*>\([^<]*\)<\/\(pubDate\|updated\)>.*<\/\(item\|entry\)>[\n\r]*//ig' '+$d' '+wq' './00-pubdates.lst' >& /dev/null

if( ! ${?quiet} ) printf "[done]\n"
printf "[done]\n" >> "${download_log}"


# Grabs the enclosures from the feed.
# This 1st method only grabs one enclosure per item/entry.
if( ! ${?quiet} ) printf "Finding enclosures . . . this may take a few moments\t\t\t\t"
printf "Finding enclosures . . . this may take a few moments\t\t\t\t" >> "${download_log}"
cp '00-feed.xml' '00-enclosures-01.lst'

# Concatinates all data into one single string:
ex '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-enclosures-01.lst' >& /dev/null

ex '+1,$s/<\/\(item\|entry\)>/\<\/\1\>\r/ig' '+1,$s/.*<\(item\|entry\)>.*<title[^>]*>\(.*\)<\/title>.*<.*enclosure[^>]*\(url\|href\)=["'\'']\([^"'\'']\+\)["'\''].*<\/\(item\|entry\)>$/\4/ig' '+1,$s/.*<\(item\|entry\)>.*<title[^>]*>\([^<]*\)<\/title>.*<\/\(item\|entry\)>[\n\r]*//ig' '+$d' '+wq' '00-enclosures-01.lst' >& /dev/null
ex '+1,$s/^[\ \s\r\n]\+//g' '+1,$s/[\ \s\r\n]\+$//g' '+1,$s/?/\\?/g' '+wq' './00-enclosures-01.lst' >& /dev/null

# This second method grabs all enclosures.
cp '00-feed.xml' '00-enclosures-02.lst'

# Concatinates all data into one single string:
ex '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-enclosures-02.lst' >& /dev/null

/usr/bin/grep --perl-regex '.*<.*enclosure[^>]*>.*' './00-enclosures-02.lst' | sed 's/.*url=["'\'']\([^"'\'']\+\)["'\''].*/\1/gi' | sed 's/.*<link[^>]\+href=["'\'']\([^"'\'']\+\)["'\''].*/\1/gi' | sed 's/^\(http:\/\/\).*\(http:\/\/.*$\)/\2/gi' | sed 's/<.*>[\r\n]\+//ig' >! './00-enclosures-02.lst'
ex '+1,$s/^[\ \s\r\n]\+//g' '+1,$s/[\ \s\r\n]\+$//g' '+1,$s/?/\\?/g' '+wq' './00-enclosures-02.lst' >& /dev/null

set enclosure_count_01 = `cat "./00-enclosures-01.lst"`
set enclosure_count_02 = `cat "./00-enclosures-02.lst"`
if( ${#enclosure_count_01} >= ${#enclosure_count_02} ) then
	mv "./00-enclosures-01.lst" "./00-enclosures.lst"
	rm "./00-enclosures-02.lst"
else
	mv "./00-enclosures-02.lst" "./00-enclosures.lst"
	rm "./00-enclosures-01.lst"
endif
if( ! ${?quiet} ) printf "[done]\n"
printf "[done]\n" >> "${download_log}"

if( ! ${?quiet} ) printf "Beginning to download: %s\n" "${title}"
printf "Beginning to download: %s\n" "${title}" >> "${download_log}"
set episodes = ();
if( ${?download_first} ) then
	if( ${#download_first} > 0 ) then
		printf "Downloading %s's %d episodes\n" "${title}" "${download_first}";
		set download_first="`printf '%d+1\n' '${download_first}' | bc`";
		ex -E -n -X --noplugin "+${download_first},${eol}d" "+wq" './00-enclosures.lst' >& /dev/null;
		ex -E -n -X --noplugin "+${download_first},${eol}d" "+wq" './00-titles.lst' >& /dev/null;
	endif
endif
if( ${?first_episodes} ) then
	if( ${#first_episodes} > 0 ) then
		ex -E -n -X --noplugin "+1,${first_episodes}d" '+wq' './00-enclosures.lst' >& /dev/null;
		ex -E -n -X --noplugin "+1,${first_episodes}d" '+wq' './00-titles.lst' >& /dev/null;
	endif
endif

if( ${?last_episodes} ) then
	if( ${#last_episodes} > 0 ) then
		tail -${last_episodes} './00-enclosures.lst' >! './00-enclosures.lst.tmp'; >& /dev/null;
		mv './00-enclosures.lst.tmp' './00-enclosures.lst'; >& /dev/null;
		tail -${last_episodes} './00-titles.lst' >! './00-titles.lst.tmp' >& /dev/null;
		mv './00-titles.lst.tmp' './00-titles.lst' >& /dev/null;
	endif
endif

set episodes = "`cat './00-enclosures.lst'`"

goto download_episodes

continue_download:
rm  "../00-feed.xml"
set episodes = "`cat './00-enclosures.lst'`"

download_episodes:

if( ! ${?quiet} ) printf "\n\tI have found %s episodes of:\n\t\t'%s'\n\n" "${#episodes}" "${title}"
printf "\n\tI have found %s episodes of:\n\t\t'%s'\n\n" "${#episodes}" "${title}" >! "${download_log}"

@ episodes_downloaded=0;
@ episode_number=0;
foreach episode ( $episodes )
	@ episode_number++;
	set episode = `echo "${episode}" | sed 's/[\r\n]$//'`
	set episodes_file = `basename ${episode}`
	set extension = `printf '%s' "${episodes_file}" | sed 's/.*\.\([^.]*\)$/\1/'`

	set episodes_pubdate = "`cat './00-pubdates.lst' | head -${episode_number} | tail -1 | sed 's/[\r\n]//g' | sed 's/\?//g'`"
	
	set episodes_title = "`cat './00-titles.lst' | head -${episode_number} | tail -1 | sed 's/[\r\n]//g' | sed 's/\?//g'`"
	
	if( "${episodes_title}" == "" ) set episodes_title = `printf '%s' "${episodes_filename}" | sed 's/\(.*\)\.[^.]*$/\1/'`
	
	if( "${episodes_pubdate}" != "" ) then
		set episodes_filename = "${episodes_title}, released on: ${episodes_pubdate}.${extension}";
	else
		set episodes_filename = "${episodes_title}.${extension}";
	endif
	
	if( ! ${?quiet} ) printf "\n\n\t\tFound episode: %s\n\t\tTitle: %s\n\t\tReleased on: %s\n\t\tURL: %s\n\t\t\t" "${episodes_title}" "${episodes_title}" "${episodes_pubdate}" "${episode}";
	printf "\n\n\t\tDownloading episode: %s\n\t\tTitle: %s\n\t\tReleased on: %s\n\t\tFilename: %s\n\t\tRemote file: %s\n\t\tURL: %s\n\t\t\t" ${episode_number} "${episodes_title}" "${episodes_pubdate}" "${episodes_filename}" "${episodes_file}" "${episode}" >> "${download_log}"

	# Skipping existing files.
	if( -e "./${episodes_filename}" ) then
		if( ! ${?quiet} ) printf "[skipped existing file]\n\n"
		printf "[skipping existing file]\n\n" >> "${download_log}"
		continue
	endif
	
	switch ( "${episodes_file}" )
	case "theend.mp3":
	case "caughtup.mp3":
	case "caught_up_1.mp3":
		if( ! ${?quiet} ) printf "[skipping podiobook.com notice]\n\n"
		printf "[skipping podiobook.com notice]\n\n" >> "${download_log}"
		continue
		breaksw
	endsw

	if( ${?regex_match_titles} ) then
		if( "`echo ${episodes_title} | s/.*\(${regex_match_titles}\).*/\1/g'`" )=="${regex_match_titles}" ) then
			printf "[skipping regexp matched episode]";
			continue;
		endif
	endif

	wget --quiet -O "./${episodes_filename}" "${episode}"
	if( ! -e "./${episodes_filename}" ) then
		if( ! ${?quiet} ) printf "[*epic fail* :(]\n\n"
		printf "[*pout* :(]\n\n" >> "${download_log}"
	else
		if( ! ${?quiet} ) printf "[*w00t\!*, FTW\!]\n\n"
		@ episodes_downloaded++;
		printf "[*w00t\!*, FTW\!]\n\n" >> "${download_log}"
	endif
end

if( ! ${?quiet} ) printf "*w00t\!*, I'm done; enjoy online media at its best!"
printf "*w00t\!*, I'm done; enjoy online media at its best!" >> "${download_log}"

if(!( ${?2} && "${2}" == "---enable-debug" )) rm './00-titles.lst' './00-enclosures.lst' './00-pubdates.lst' './00-feed.xml'

