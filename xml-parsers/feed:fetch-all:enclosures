#!/bin/tcsh -f
if(! ${?1} || "${1}" == "" || "${1}" == "--help" ) then
	printf "Usage: %s [ (--newest|--first)=1..10..? ] [ (--oldest|--last)=1..10..? ] [ --quit ] RSS_URI\n" `basename ${0}`;
	exit -1;
endif

while( "${1}" != "" )
	set attrib="`printf '${1}' | sed 's/\-\-\([^=]*\)=\?\(.*\)/\1/g'`";
	set value="`printf '${1}' | sed 's/\-\-\([^=]*\)=\?\(.*\)/\2/g'`";
	
	switch ( "${attrib}" )
	case "newest":
	case "first":
		if( ${?value} && "${value}" != "" && ${value} > 0 ) then
			set download_first="${value}";
		else
			set download_first="1";
		endif
		breaksw;
	
	case "start-with-episode":
	case "start-with":
	case "start-at-episode":
	case "start-at":
		if( ${?value} && "${value}" != "" && ${value} > 0 ) then
			set first_episodes="${value}";
		else
			set first_episodes="1";
		endif
		breaksw;
	
	case "oldest":
	case "last":
	case "stop-with-episode":
	case "stop-with":
	case "stop-at-episode":
	case "stop-at":
	case "download-limit":
		if( ${?value} && "${value}" != "" && ${value} > 0 ) then
			set last_episodes="${value}";
		else
			set last_episodes="1";
		endif
		breaksw;
	
	case "quiet":
		set quiet;
		breaksw;
		
	case "f":
	case "force":
	case "force-fetch":
	case "force-all":
		set force_all;
		breaksw;
	
	case "save-to":
	case "download-to":
	case "download-dir":
	case "download-directory":
		if( "${value}" != "" && -d "${value}" ) then
			set download_dir="${value}";
		else if( ${?2} && "${2}" != "" && -d "${2}" ) then
			set download_dir="${2}";
			shift;
		endif
		breaksw;
	
	case "regex-match-titles":
		if( "${value}" == "" ) breaksw;
		set regex_match_titles="${value}";
		breaksw;
	
	default:
		set feed="${1}";
		breaksw;
	endsw
	shift;
end	

if(! ${?download_dir} ) then
	if( "`basename '${0}' | sed -r 's/^(alacast).*/\1/ig'`" == "alacast" && -e "${HOME}/.alacast/profiles/${USER}/alacast.ini" ) then
		set download_dir="`cat '${HOME}/.alacast/profiles/${USER}/alacast.ini' | /bin/grep --perl-regexp 'save_to_path.*' | /bin/sed -r 's/.*[^=]*=["\""'\'']([^"\""'\'']*)["\""'\''];/\1/'`";
		if( "${download_dir}" != "${cwd}" ) then
			set starting_dir="${cwd}";
			cd "${download_dir}";
		endif
	endif
endif

if( ${?download_dir} ) then
	if( "${download_dir}" != "${cwd}" ) then
		if(! -d "${download_dir}" ) mkdir -p "${download_dir}";
		set starting_dir="${cwd}";
		cd "${download_dir}";
	endif
	unset download_dir;
endif

set please_wait_phrase="...please be patient, I may need several moments.\t\t";

if( ! ${?quiet} ) printf "Downloading podcast's feed.\n\t<%s>\n" "${feed}";
wget --quiet -O './00-feed.xml' "${feed}";
ex -E -n -X '+1,$s/^<!\-\-.*\-\->[\r\n]/' '+wq' './00-feed.xml' > /dev/null;

if( ! ${?quiet} ) printf "Finding feed's title.\n";
set title="`/usr/bin/grep '<title.*>' './00-feed.xml' | sed 's/.*<title[^>]*>\([^<]*\)<\/title>.*/\1/gi' | head -1 | sed 's/[\r\n]//g' | sed 's/\//\ \-\ /g' | sed  's/[\ \t]*\&[^;]\+\;[\ \t]*/\ /ig'`";

if( ! -d "${title}" ) mkdir -p "${title}";
cd "${title}";

set download_log="./00-"`basename "${0}"`".log";
touch "${download_log}";

if( ! ${?quiet} ) printf "Preparing to download: %s\n" "${title}";
printf "Preparing to download: %s\n" "${title}" >> "${download_log}";
if( ! ${?quiet} ) printf "\tURI:\t[%s]\n" "${feed}";
printf "\tURI:\t[%s]\n" "${feed}" >> "${download_log}";

if( -e './00-feed.xml' && -e './00-titles.lst' && -e './00-enclosures.lst' && -e './00-pubdates.lst' ) goto continue_download;

# This to make sure we're working with UNIX file types & don't have to repeat newline replacement.
cp '../00-feed.xml' "./00-feed.xml";
rm '../00-feed.xml'

# Grabs the titles of the podcast and all episodes.
if( ! ${?quiet} ) printf "Finding title${please_wait_phrase}\t";
printf "Finding titles${please_wait_phrase}\t" >> "${download_log}";

# Puts each item, or entry, on its own line:
ex -E -n -X '+1,$s/[\r\n]\+[\ \t]*//' '+wq' './00-feed.xml' >& /dev/null;
ex -E -n -X '+1,$s/[\r\n]\+[\ \t]*//' '+1,$s/<\/\(item\|entry\)>/\<\/\1\>\r/ig' '+$d' '+wq' './00-feed.xml' >& /dev/null;

cp './00-feed.xml' './00-titles.lst';

ex -E -n -X '+1,$s/.*<\(item\|entry\)[^>]*>.*<title[^>]*>\(.*\)<\/title>.*\(enclosure\).*<\/\(item\|entry\)>$/\2/ig' '+1,$s/.*<\(item\|entry\)[^>]*>.*\(enclosure\).*<title[^>]*>\(.*\)<\/title>.*<\/\(item\|entry\)>$/\3/ig' '+1,$s/.*<\(item\|entry\)[^>]*>.*<title[^>]*>\([^<]*\)<\/title>.*<\/\(item\|entry\)>[\n\r]*//ig' '+wq' './00-titles.lst' >& /dev/null;

ex -E -n -X '+1,$s/&\(#038\|amp\)\;/\&/ig' '+1,$s/&\(#8243\|#8217\|#8220\|#8221\|\#039\|rsquo\|lsquo\)\;/'\''/ig' '+1,$s/&[^;]\+\;[\ \t]*/\ /ig' '+1,$s/<\!\[CDATA\[\(.*\)\]\]>/\1/g' '+1,$s/#//g' '+1,$s/\//\ \-\ /g' '+wq' './00-titles.lst' >& /dev/null;
if( ! ${?quiet} )printf "[done]\n";
printf "[done]\n" >> "${download_log}";

# This will be my last update to any part of Alacast v1
# This fixes episode & chapter titles so that they will sort correctly
if( ! ${?quiet} ) printf "Formating titles${please_wait_phrase}";
printf "Formating titles${please_wait_phrase}" >> "${download_log}";
ex -E -n -X '+1,$s/^\(Zero\)/0/gi' '+1,$s/^\(One\)/1/gi' '+1,$s/^\(Two\)/2/gi' '+1,$s/^\(Three\)/3/gi' '+1,$s/^\(Four\)/4/gi' '+1,$s/^\(Five\)/5/gi' '+wq' './00-titles.lst' >& /dev/null;
ex -E -n -X '+1,$s/^\(Six\)/6/gi' '+1,$s/^\(Seven\)/7/gi' '+1,$s/^\(Eight\)/8/gi' '+1,$s/^\(Nine\)/9/gi' '+1,$s/^\(Ten\)/10/gi' '+wq' './00-titles.lst' >& /dev/null;

ex -E -n -X '+1,$s/^\([0-9]\)ty/\10/gi' '+1,$s/^\(Fifty\)/50/gi' '+1,$s/^\(Thirty\)/30/gi' '+1,$s/^\(Twenty\)/20/gi' '+wq' './00-titles.lst' >& /dev/null;
ex -E -n -X '+1,$s/^\([0-9]\)teen/1\1/gi' '+1,$s/^\(Fifteen\)/15/gi' '+1,$s/^\(Thirteen\)/13/gi' '+1,$s/^\(Twelve\)/12/gi' '+1,$s/^\(Eleven\)/11/gi' '+wq' './00-titles.lst' >& /dev/null;

ex -E -n -X '+1,$s/\([^a-zA-Z]\)\(Zero\)/\10/gi' '+1,$s/\([^a-zA-Z]\)\(One\)/\11/gi' '+1,$s/\([^a-zA-Z]\)\(Two\)/\12/gi' '+1,$s/\([^a-zA-Z]\)\(Three\)/\13/gi' '+1,$s/\([^a-zA-Z]\)\(Four\)/\14/gi' '+1,$s/\([^a-zA-Z]\)\(Five\)/\15/gi' '+wq' './00-titles.lst' >& /dev/null;
ex -E -n -X '+1,$s/\([^a-zA-Z]\)\(Six\)/\16/gi' '+1,$s/\([^a-zA-Z]\)\(Seven\)/\17/gi' '+1,$s/\([^a-zA-Z]\)\(Eight\)/\18/gi' '+1,$s/\([^a-zA-Z]\)\(Nine\)/\19/gi' '+1,$s/\([^a-zA-Z]\)\(Ten\)/\110/gi' '+wq' './00-titles.lst' >& /dev/null;

ex -E -n -X '+1,$s/\([^a-zA-Z]\)\([0-9]\)ty[^a-zA-Z]/\1\20/gi' '+1,$s/\([^a-zA-Z]\)\(Fifty\)\([^a-zA-Z]\)/\150\3/gi' '+1,$s/\([^a-zA-Z]\)\(Thirty\)\([^a-zA-Z]\)/\130\3/gi' '+1,$s/\([^a-zA-Z]\)\(Twenty\)\([^a-zA-Z]\)/\120\3/gi' '+wq' './00-titles.lst' >& /dev/null;
ex -E -n -X '+1,$s/\([^a-zA-Z]\)\([0-9]\)teen\([^a-zA-Z]\)/\11\2\3/gi' '+1,$s/\([^a-zA-Z]\)\(Fifteen\)\([^a-zA-Z]\)/\115\3/gi' '+1,$s/\([^a-zA-Z]\)\(Thirteen\)\([^a-zA-Z]\)/\113\3/gi' '+1,$s/\([^a-zA-Z]\)\(Twelve\)\([^a-zA-Z]\)/\112\3/gi' '+1,$s/\([^a-zA-Z]\)\(Eleven\)\([^a-zA-Z]\)/\111\3/gi' '+wq' './00-titles.lst' >& /dev/null;

ex -E -n -X '+1,$s/\([^a-zA-Z]\)\([0-9]\)ty/\1\20$/gi' '+1,$s/\([^a-zA-Z]\)\(Fifty\)/\150/gi' '+1,$s/\([^a-zA-Z]\)\(Thirty\)/\130/gi' '+1,$s/\([^a-zA-Z]\)\(Twenty\)/\120/gi' '+wq' './00-titles.lst' >& /dev/null;
ex -E -n -X '+1,$s/\([^a-zA-Z]\)\([0-9]\)teen/\11\2$/gi' '+1,$s/\([^a-zA-Z]\)\(Fifteen\)/\115/gi' '+1,$s/\([^a-zA-Z]\)\(Thirteen\)/\113/gi' '+1,$s/\([^a-zA-Z]\)\(Twelve\)/\112/gi' '+1,$s/\([^a-zA-Z]\)\(Eleven\)/\111/gi' '+wq' './00-titles.lst' >& /dev/null;

ex -E -n -X '+1,$s/^\([0-9]\{1\}\)\([^0-9]\{1\}\)/0\1\2/' '+1,$s/\([^0-9]\{1\}\)\([0-9]\{1\}\)\([^0-9]\{1\}\)/\10\2\3/g' '+1,$s/\([^0-9]\{1\}\)\([0-9]\{1\}\)$/\10\2/' '+wq' './00-titles.lst' >& /dev/null;

ex -E -n -X '+1,$s/\//\ \-\ /g' '+1,$s/[\ ]\{2,\}/\ /g' '+wq' './00-titles.lst' >& /dev/null;
if( ! ${?quiet} ) printf "[done]\n";
printf "[done]\n" >> "${download_log}";


# Grabs the release dates of the podcast and all episodes.
if( ! ${?quiet} ) printf "Finding release dates...please be patient, I may need several moments\t\t";
printf "Finding release dates${please_wait_phrase}\t\t" >> "${download_log}";
cp './00-feed.xml' './00-pubdates.lst';

# Concatinates all data into one single string:
ex -E -n -X '+1,$s/.*<\(item\|entry\)[^>]*>.*<\(pubDate\|updated\)[^>]*>\(.*\)<\/\(pubDate\|updated\)>.*<.*enclosure[^>]*\(url\|href\)=["'\'']\([^"'\'']\+\)["'\''].*<\/\(item\|entry\)>$/\3/ig' '+1,$s/.*<\(item\|entry\)[^>]*>.*<.*enclosure[^>]*\(url\|href\)=["'\'']\([^"'\'']\+\)["'\''].*<\(pubDate\|updated\)[^>]*>\(.*\)<\/\(pubDate\|updated\)>.*<\/\(item\|entry\)>$/\5/ig' '+1,$s/.*<\(item\|entry\)[^>]*>.*<\(pubDate\|updated\)[^>]*>\([^<]*\)<\/\(pubDate\|updated\)>.*<\/\(item\|entry\)>[\n\r]*//ig' '+wq' './00-pubdates.lst' >& /dev/null;


if( ! ${?quiet} ) printf "[done]\n";
printf "[done]\n" >> "${download_log}";


# Grabs the enclosures from the feed.
# This 1st method only grabs one enclosure per item/entry.
if( ! ${?quiet} ) printf "Finding enclosures . . . this may take a few moments\t\t\t\t";
printf "Finding enclosures . . . this may take a few moments\t\t\t\t" >> "${download_log}";
cp '00-feed.xml' '00-enclosures-01.lst';

ex -E -n -X '+1,$s/.*<\(item\|entry\)[^>]*>.*<.*enclosure[^>]*\(url\|href\)=["'\'']\([^"'\'']\+\)["'\''].*<\/\(item\|entry\)>$/\3/ig' '+1,$s/.*<\(item\|entry\)[^>]*>.*<\/\(item\|entry\)>[\n\r]*//ig' '+wq' '00-enclosures-01.lst' >& /dev/null;
ex -E -n -X '+1,$s/^[\ \s\r\n]\+//g' '+1,$s/[\ \s\r\n]\+$//g' '+1,$s/?/\\?/g' '+wq' './00-enclosures-01.lst' >& /dev/null;

# This second method grabs all enclosures.
cp '00-feed.xml' '00-enclosures-02.lst';

# Concatinates all data into one single string:
ex -E -n -X '+1,$s/[\r\n]\+[\ \t]*//g' '+wq' './00-enclosures-02.lst' >& /dev/null;

/usr/bin/grep --perl-regex '.*<.*enclosure[^>]*>.*' './00-enclosures-02.lst' | sed 's/.*url=["'\'']\([^"'\'']\+\)["'\''].*/\1/gi' | sed 's/.*<link[^>]\+href=["'\'']\([^"'\'']\+\)["'\''].*/\1/gi' | sed 's/^\(http:\/\/\).*\(http:\/\/.*$\)/\2/gi' | sed 's/<.*>[\r\n]\+//ig' >! './00-enclosures-02.lst';
ex -E -n -X '+1,$s/^[\ \s\r\n]\+//g' '+1,$s/[\ \s\r\n]\+$//g' '+1,$s/?/\\?/g' '+wq' './00-enclosures-02.lst' >& /dev/null;

set enclosure_count_01=`cat "./00-enclosures-01.lst"`;
set enclosure_count_02=`cat "./00-enclosures-02.lst"`;
if( ${#enclosure_count_01} >= ${#enclosure_count_02} ) then
	mv "./00-enclosures-01.lst" "./00-enclosures.lst";
	rm "./00-enclosures-02.lst";
else
	mv "./00-enclosures-02.lst" "./00-enclosures.lst";
	rm "./00-enclosures-01.lst";
endif
if( ! ${?quiet} ) printf "[done]\n";
printf "[done]\n" >> "${download_log}";

if( ! ${?quiet} ) printf "Beginning to download: %s\n" "${title}";
printf "Beginning to download: %s\n" "${title}" >> "${download_log}";
set episodes=();
if( ${?download_first} ) then
	if( ${#download_first} > 0 ) then
		printf "Downloading %s's %d episodes\n" "${title}" "${download_first}";
		set download_first="`printf '%d+1\n' '${download_first}' | bc`";
		ex -E -n -X --noplugin "+${download_first},${eol}d" "+wq" './00-enclosures.lst' >& /dev/null;
		ex -E -n -X --noplugin "+${download_first},${eol}d" "+wq" './00-titles.lst' >& /dev/null;
		ex -E -n -X --noplugin "+${download_first},${eol}d" "+wq" './00-pubDates.lst' >& /dev/null;
	endif
endif
if( ${?first_episodes} ) then
	if( ${#first_episodes} > 0 ) then
		ex -E -n -X --noplugin "+1,${first_episodes}d" '+wq' './00-enclosures.lst' >& /dev/null;
		ex -E -n -X --noplugin "+1,${first_episodes}d" '+wq' './00-titles.lst' >& /dev/null;
		ex -E -n -X --noplugin "+1,${first_episodes}d" '+wq' './00-pubDates.lst' >& /dev/null;
	endif
endif

if( ${?last_episodes} ) then
	if( ${#last_episodes} > 0 ) then
		tail -${last_episodes} './00-enclosures.lst' >! './00-enclosures.lst.tmp'; >& /dev/null;
		mv './00-enclosures.lst.tmp' './00-enclosures.lst'; >& /dev/null;
		tail -${last_episodes} './00-titles.lst' >! './00-titles.lst.tmp' >& /dev/null;
		mv './00-titles.lst.tmp' './00-titles.lst' >& /dev/null;
	endif
endif

set episodes="`cat './00-enclosures.lst'`";

goto download_episodes;

continue_download:
rm  "../00-feed.xml";
set episodes="`cat './00-enclosures.lst'`";

download_episodes:

if( ! ${?quiet} ) printf "\n\tI have found %s episodes of:\n\t\t'%s'\n\n" "${#episodes}" "${title}";
printf "\n\tI have found %s episodes of:\n\t\t'%s'\n\n" "${#episodes}" "${title}" >! "${download_log}";

@ episodes_downloaded=0;
@ episodes_number=0;
if(! ${?eol} ) set eol='$';
foreach episode ( "`cat './00-enclosures.lst'`" )
	@ episodes_number++;
	if( ${episodes_number} > 1 ) then
		if( ! ${?quiet} ) printf "\n\n";
		printf "\n\n" >> "${download_log}";
	endif
	
	set episode=`echo "${episode}" | sed 's/[\r\n]$//'`;
	set episodes_file="`echo '${episode}' | sed -r 's/.*\/([^\/]+)\\?\?.*${eol}/\1/'`";
	set extension=`printf '%s' "${episodes_file}" | sed 's/.*\.\([^.]*\)$/\1/'`;
	
	set episodes_pubdate="`cat './00-pubdates.lst' | head -${episodes_number} | tail -1 | sed 's/[\r\n]//g' | sed 's/\?//g'`";
	
	set episodes_title="`cat './00-titles.lst' | head -${episodes_number} | tail -1 | sed 's/[\r\n]//g' | sed 's/\?//g'`";
	
	if( "${episodes_title}" == "" ) set episodes_title=`printf '%s' "${episodes_file}" | sed 's/\(.*\)\.[^.]*$/\1/'`;
	
	if( "${episodes_pubdate}" != "" ) then
		set episodes_filename="${episodes_title}, released on: ${episodes_pubdate}.${extension}";
	else
		set episodes_filename="${episodes_title}.${extension}";
	endif
	
	if(! ${?quiet} ) printf "\n\n\t\tDownloading episode: %s(episodes_number)\n\t\tTitle: %s (episodes_title)\n\t\tReleased on: %s (episodes_pubDate)\n\t\tFilename: %s (episodes_filename)\n\t\tRemote file: %s (episodes_file)\n\t\tURL: %s (episode)\n\t\t\t" ${episodes_number} "${episodes_title}" "${episodes_pubdate}" "${episodes_filename}" "${episodes_file}" "${episode}";
	printf "\n\n\t\tDownloading episode: %s(episodes_number)\n\t\tTitle: %s (episodes_title)\n\t\tReleased on: %s (episodes_pubDate)\n\t\tFilename: %s (episodes_filename)\n\t\tRemote file: %s (episodes_file)\n\t\tURL: %s (episode)\n\t\t\t" ${episodes_number} "${episodes_title}" "${episodes_pubdate}" "${episodes_filename}" "${episodes_file}" "${episode}" >> "${download_log}";

	# Skipping existing files.
	if(! ${?fetch_all} ) then
		if( -e "./${episodes_filename}" ) then
			if( ! ${?quiet} ) printf "[skipped existing file]";
			printf "[skipping existing file]" >> "${download_log}";
			continue;
		endif
		
		switch ( "`basename '${episodes_file}'`" )
			case "theend.mp3":
			case "caughtup.mp3":
			case "caught_up_1.mp3":
				if( ! ${?quiet} ) printf "[skipping podiobook.com notice]";
				printf "[skipping podiobook.com notice]" >> "${download_log}";
				continue
				breaksw;
		endsw
		
		if( "`echo "\""${episodes_title}"\"" | sed -r 's/.*(commentary).*/\1/ig'`" != "${episodes_title}" ) then
			if( ! ${?quiet} ) printf "[skipping commentary track]";
			printf "[skipping commentary track]" >> "${download_log}";
			continue;
		endif
		
		if( ${?regex_match_titles} ) then
			if( "`echo "\""${episodes_title}"\"" | sed -r s/.*\(${regex_match_titles}\).*/\1/ig'`" )!="${episodes_title}" ) then
				printf "[skipping regexp matched episode]";
				continue;
			endif
		endif
	endif
	
	wget --quiet -O "./${episodes_filename}" "${episode}"
	
	if( ! -e "./${episodes_filename}" ) then
		if( ! ${?quiet} ) printf "[*epic fail* :(]";
		printf "[*pout* :(]" >> "${download_log}";
	else
		if( ! ${?quiet} ) printf "[*w00t\!*, FTW\!]";
		@ episodes_downloaded++;
		printf "[*w00t\!*, FTW\!]" >> "${download_log}";
	endif
end

if( ! ${?quiet} ) printf "\n\n*w00t\!*, I'm done; enjoy online media at its best!";
printf "\n\n*w00t\!*, I'm done; enjoy online media at its best!" >> "${download_log}";

if(!( ${?2} && "${2}" == "---enable-debug" )) rm './00-titles.lst' './00-enclosures.lst' './00-pubdates.lst' './00-feed.xml';

if( ${?starting_dir} ) then
	cd "${starting_dir}";
endif

